---
layout: post
title:  "RPC"
date:   2019-06-30 22:24:00
categories: 面试
---

## redis

**redis有哪些架构**

1. 单机版
	* 特点
		* 简单。
	* 问题
		* 内存容量有限。
		* 处理能力有限。
		* 无法高可用。
2. 主从复制
	* 特点：
		* 具有master/slave角色。
		* master/slave数据相同。
		* 降低master读压力，读数据转交到从库。

	* 问题
		* 无法保证高可用。
		* 没有解决master写的压力。

3. 哨兵

	Redis sentinel 是一个分布式系统中监控 redis 主从服务器，并在主服务器下线时自动进行故障转移。
	* 特性：
		* 监控：会不断地检查你的主服务器和从服务器是否运作正常。
		* 提醒：当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。
		* 自动故障迁移： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。
	* 特点：
		* 	保证高可用。
		*  监控各个节点。
		*  自动故障迁移。
	* 缺点：
		* 主从模式，切换需要时间丢数据。
		* 没有解决master的写压力。

4. 集群

	redis cluster，主要是针对海量数据+高并发+高可用的场景，海量数据，如果你的数据量很大，那么建议就用redis cluster。
	* 将数据进行分片，每个master上放一部分数据。
	* 提供高可用支持，部分master不可用时，可以继续工作。

	* 支撑N个redis master node，每个master node都可以挂载多个slave node
高可用，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master。

4.1 集群代理型

* 特点
	* 多种hash算法：MD5、CRC16、CRC32、CRC32a、hsieh、murmur、Jenkins。
	* 支持失败节点的自动删除。
	* 后端分片逻辑对业务透明，业务方的读写方式和操作单个 Redis 一致。
* 缺点
	* 增加新的proxy,需要维护其高可用。

4.2 集群直连型

采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。
	
* 特点
	* 无中心架构（不存在哪个节点影响性能瓶颈），少了 proxy 层。
	* 数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。
	* 可扩展性，可线性扩展到 1000 个节点，节点可动态添加或删除。
	* 高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做备份数据副本。
	* 实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave到 Master 的角色提升。
* 缺点
	* 资源隔离性较差，容易出现相互影响的情况。
	* 数据通过异步复制,不保证数据的强一致性。

**数据分布算法**

1. 顺序分布
	* 数据分散易倾斜
	* 键值业务相关
	* 可顺序访问
	* 支持批量操作

2. 哈希分布
	* 数据分散度高
	* 键值分布业务无关
	* 无法顺序访问
	* 支持批量操作

**哈希分布分类**

* 节点取余区
* 一致性哈希分区
* 虚拟槽分区。

[数据分布理论](https://blog.csdn.net/qq_27862335/article/details/81771812)

[一致性哈希](https://www.cnblogs.com/lpfuture/p/5796398.html)


**一致性Hash性质**

* 平衡性(Balance)
* 单调性
* 分散性
* 负载
* 平滑性

## RPC中间件

* 基于远程过程调用的中间件，允许一个应用程序中的过程调用远程应用程序中的过程，就好像它们是本地调用一样。该中间件实现一个查找远程过程的链接机制并使调用方能够以透明方式使用这些过程。以前，这种类型的中间件处理基于过程的程序；现在，它还包括基于对象的组件。
* 基于对象请求代理 (Object Request Broker, ORB) 的中间件，使应用程序的对象能够在异类网络之间分布和共享。
* 面向消息的中间件或基于 MOM 的中间件，使分布式应用程序可以通过发送和接收消息来进行通信和交换数据。


## RPC

**常见rpc框架**

* Netty - Netty框架不局限于RPC，更多的是作为一种网络协议的实现框架，比如HTTP，由于RPC需要高效的网络通信，就可能选择以Netty作为基础。

* brpc是一个基于protobuf接口的RPC框架，在百度内部称为“baidu-rpc”，它囊括了百度内部所有RPC协议，并支持多种第三方协议，从目前的性能测试数据来看，brpc的性能领跑于其他同类RPC产品。
Dubbo是Alibaba开发的一个RPC框架，远程接口基于Java Interface, 依托于Spring框架。

* gRPC的Java实现的底层网络库是基于Netty开发而来，其Go实现是基于net库。
* Thrift是Apache的一个项目(http://thrift.apache.org)，前身是Facebook开发的一个RPC框架，采用thrift作为IDL (Interface description language)。
* jsonrpc。

[学习链接](https://www.jianshu.com/p/b0343bfd216e)

## RPC问题

**rpc解决的三个问题**

RPC要达到的目标：远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。

* Call ID映射。

	在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 <--> Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。

* 序列化和反序列化。

	需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。

* 网络传输。

	远程调用往往是基于网络的，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西。

## memcached
[学习链接](http://youzhixueyuan.com/memcached-answers-to-interview-questions.html)

**memcache与redis的区别和联系**

* 存储方式不同

	memecache 把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小；redis有部份存在硬盘上，这样能保证数据的持久性，支持数据的持久化（笔者注：有快照和AOF日志两种持久化方式，在实际应用的时候，要特别注意配置文件快照参数，要不就很有可能服务器频繁满载做dump）。 

* 数据支持类型不同

	redis在数据支持上要比memecache多的多。

* 使用底层模型不同

	新版本的redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 

* 运行环境不同 
redis目前官方只支持LINUX 上去行，从而省去了对于其它系统的支持，这样的话可以更好的把精力用于本系统 环境上的优化，虽然后来微软有一个小组为其写了补丁。

**Redis支持数据的冷热处理**

Redis的数据全部放在内存带来了高速的性能，但是也带来一些不合理之处。比如一个中型网站有100万注册用户，如果这些资料要用Redis来存储，内存的容量必须能够容纳这100万用户。但是业务实际情况是100万用户只有5万活跃用户，1周来访问过1次的也只有15万用户，因此全部100万用户的数据都放在内存有不合理之处，RAM需要为冷数据买单。
这跟操作系统非常相似，操作系统所有应用访问的数据都在内存，但是如果物理内存容纳不下新的数据，操作系统会智能将部分长期没有访问的数据交换到磁盘，为新的应用留出空间。现代操作系统给应用提供的并不是物理内存，而是虚拟内存(Virtual Memory)的概念。
基于相同的考虑，Redis 2.0也增加了VM特性。让Redis数据容量突破了物理内存的限制。并实现了数据冷热分离。

**Redis的VM实现是重复造轮子**

Redis的VM依照之前的epoll实现思路依旧是自己实现。但是在前面操作系统的介绍提到OS也可以自动帮程序实现冷热数据分离，Redis只需要OS申请一块大内存，OS会自动将热数据放入物理内存，冷数据交换到硬盘，另外一个知名的“理解了现代操作系统(3)”的Varnish就是这样实现，也取得了非常成功的效果。
作者antirez在解释为什么要自己实现VM中提到几个原因(6)。主要OS的VM换入换出是基于Page概念，比如OS VM1个Page是4K, 4K中只要还有一个元素即使只有1个字节被访问，这个页也不会被SWAP, 换入也同样道理，读到一个字节可能会换入4K无用的内存。而Redis自己实现则可以达到控制换入的粒度。另外访问操作系统SWAP内存区域时block进程，也是导致Redis要自己实现VM原因之一。

**用get/set方式使用Redis**

作为一个key value存在，很多开发者自然的使用set/get方式来使用Redis，实际上这并不是最优化的使用方法。尤其在未启用VM情况下，Redis全部数据需要放入内存，节约内存尤其重要。
假如一个key-value单元需要最小占用512字节，即使只存一个字节也占了512字节。这时候就有一个设计模式，可以把key复用，几个key-value放入一个key中，value再作为一个set存入，这样同样512字节就会存放10-100倍的容量。
这就是为了节约内存，建议使用hashset而不是set/get的方式来使用Redis，详细方法见参考文献(7)。

**使用aof代替snapshot**

Redis有两种存储方式，默认是snapshot方式，实现方法是定时将内存的快照(snapshot)持久化到硬盘，这种方法缺点是持久化之后如果出现crash则会丢失一段数据。因此在完美主义者的推动下作者增加了aof方式。aof即append only mode，在写入内存数据的同时将操作命令保存到日志文件，在一个并发更改上万的系统中，命令日志是一个非常庞大的数据，管理维护成本非常高，恢复重建时间会非常长，这样导致失去aof高可用性本意。另外更重要的是Redis是一个内存数据结构模型，所有的优势都是建立在对内存复杂数据结构高效的原子操作上，这样就看出aof是一个非常不协调的部分。
其实aof目的主要是数据可靠性及高可用性，在Redis中有另外一种方法来达到目的：Replication。由于Redis的高性能，复制基本没有延迟。这样达到了防止单点故障及实现了高可用。

## memcache
memcache是一套分布式的对象缓存系统，基于内存的key-value存储。

**特征**

* 协议简单。
* 基于libevent的事件处理。
* 内置内存存储方式。
* memcached不互相通信的分布式。

## 待看
* csc16